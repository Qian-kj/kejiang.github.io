<!DOCTYPE html>
<html lang=en>
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MEYETR2ZN7"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-MEYETR2ZN7');
    </script>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="AuthorsKejiang Qian, Lingjun Mao, Xin Liang, Yimin Ding, Jin Gao, Xinran Wei, Ziyi Guo, and Jiajie Li Highlights Introduces an adaptable MARL framework for urban planning optimized around stakeholder">
<meta property="og:type" content="article">
<meta property="og:title" content="AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning">
<meta property="og:url" content="http://example.com/2023/10/25/ai-urban-planner/index.html">
<meta property="og:site_name" content="&quot;Brian&quot; Kejiang Qian">
<meta property="og:description" content="AuthorsKejiang Qian, Lingjun Mao, Xin Liang, Yimin Ding, Jin Gao, Xinran Wei, Ziyi Guo, and Jiajie Li Highlights Introduces an adaptable MARL framework for urban planning optimized around stakeholder">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2023/10/25/ai-urban-planner/marl_vote.png">
<meta property="og:image" content="http://example.com/2023/10/25/ai-urban-planner/actor_critic_framework.png">
<meta property="og:image" content="http://example.com/2023/10/25/ai-urban-planner/initial.png">
<meta property="og:image" content="http://example.com/2023/10/25/ai-urban-planner/cmarl.png">
<meta property="article:published_time" content="2023-10-25T15:54:40.000Z">
<meta property="article:modified_time" content="2024-02-12T22:17:56.640Z">
<meta property="article:author" content="Kejiang Qian">
<meta property="article:tag" content="Artificial Intelligence">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/10/25/ai-urban-planner/marl_vote.png">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
<meta name="generator" content="Hexo 6.3.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Gallery</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="https://scholar.google.com/citations?user=x6fPDh4AAAAJ&hl=zh-CN&oi=ao">Research</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2023/12/08/ai-nushu/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2023/07/10/degov4vc/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2023/10/25/ai-urban-planner/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2023/10/25/ai-urban-planner/&text=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2023/10/25/ai-urban-planner/&title=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2023/10/25/ai-urban-planner/&is_video=false&description=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning&body=Check out this article: http://example.com/2023/10/25/ai-urban-planner/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2023/10/25/ai-urban-planner/&title=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2023/10/25/ai-urban-planner/&title=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2023/10/25/ai-urban-planner/&title=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2023/10/25/ai-urban-planner/&title=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2023/10/25/ai-urban-planner/&name=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2023/10/25/ai-urban-planner/&t=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Authors"><span class="toc-number">1.</span> <span class="toc-text">Authors</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Highlights"><span class="toc-number">2.</span> <span class="toc-text">Highlights</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Background"><span class="toc-number">3.</span> <span class="toc-text">Background</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Aim-amp-Methodology"><span class="toc-number">4.</span> <span class="toc-text">Aim &amp; Methodology</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Results"><span class="toc-number">5.</span> <span class="toc-text">Results</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Planning-outcomes"><span class="toc-number">5.1.</span> <span class="toc-text">Planning outcomes</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Paper-link"><span class="toc-number">6.</span> <span class="toc-text">Paper link</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Kejiang Qian</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2023-10-25T15:54:40.000Z" itemprop="datePublished">2023-10-25</time>
        
      
    </div>


      

      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link-link" href="/tags/Artificial-Intelligence/" rel="tag">Artificial Intelligence</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h1 id="Authors"><a href="#Authors" class="headerlink" title="Authors"></a>Authors</h1><p><strong>Kejiang Qian</strong>, Lingjun Mao, Xin Liang, Yimin Ding, Jin Gao, Xinran Wei, Ziyi Guo, and Jiajie Li</p>
<h1 id="Highlights"><a href="#Highlights" class="headerlink" title="Highlights"></a>Highlights</h1><ul>
<li>Introduces an adaptable MARL framework for urban planning optimized around stakeholder interests.</li>
<li>Offers urban planners a versatile planning tool.</li>
<li>Shows MARL’s efficiency in uncertain environments.</li>
<li>Expands MARL’s real-world urban planning applications.</li>
<li>Links AI theory with societal needs through human-centric solutions.</li>
</ul>
<h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>In urban planning, land use readjustment plays a pivotal role in aligning land use configurations with the current demands for sustainable urban development. However, present-day urban planning practices face two main issues: </p>
<ul>
<li>Land use decisions are predominantly dependent on human experts. </li>
<li>While resident engagement in urban planning can promote urban sustainability and livability, it is challenging to reconcile the diverse interests of stakeholders.</li>
</ul>
<h1 id="Aim-amp-Methodology"><a href="#Aim-amp-Methodology" class="headerlink" title="Aim &amp; Methodology"></a>Aim &amp; Methodology</h1><p>To address these challenges, we introduce a Consensus-based Multi-Agent Reinforcement Learning framework for real-world land use readjustment. </p>
<ul>
<li>This framework serves participatory urban planning, allowing diverse intelligent agents as stakeholder representatives to vote for preferred land use types. </li>
<li>Within this framework, we propose a novel consensus mechanism in reward design to optimize land utilization through collective decision making. </li>
<li>To abstract the structure of the complex urban system, the geographic information of cities is transformed into a spatial graph structure and then processed by graph neural networks. </li>
<li>Comprehensive experiments on both traditional top-down planning and participatory planning methods from real-world communities indicate that our computational framework enhances global benefits and accommodates diverse interests, leading to improved satisfaction across different demographic groups.</li>
</ul>
<p><img src="/2023/10/25/ai-urban-planner/marl_vote.png" alt="img"><br>Figure 1: In the Consensus-based Multi-Agent Reinforce-ment Learning (MARL) framework, agents are distributed across different locations with varied observation ranges. Each agent casts a vote for its preferred land use type. The collective voting outcome determines the land use type to be readjusted in the corresponding urban parcel.<br><img src="/2023/10/25/ai-urban-planner/actor_critic_framework.png" alt="img"><br>Figure 2: In our framework, we utilize the Actor-Critic architecture. The Actor processes an initial graph to generate an action. Conversely, the Critic takes a combined input of the initial graph and the Actor’s output, subsequently producing a score for the action in its current state.</p>
<h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><h2 id="Planning-outcomes"><a href="#Planning-outcomes" class="headerlink" title="Planning outcomes"></a>Planning outcomes</h2><p>By integrating Multi-Agent Reinforcement Learning, our framework ensures that participatory urban planning decisions are more dynamic and adaptive to evolving community needs and provides a robust platform for automating complex real-world urban planning processes.</p>
<style>
  .figure-container {
    display: flex;
    justify-content: space-between; /* This will place space between the two images if there's extra room */
  }
  /* .subfigure:first-child {
    flex-basis: 50%; 
    margin-right: 5px; 
  }
  .subfigure:last-child {
    flex-basis: 55%; 
    margin-left: 5px; 
  } */
  .subfigure img {
    width: auto; /* Images will take up 95% of their .subfigure container */
    height: 300px;
  }
  .subfigure-caption {
    text-align: center;
    margin-top: 0px;
  }
  .figure-caption {
    text-align: left;
    margin-top: 0px;
  }
</style>

<div class="figure-container">
  <div class="subfigure">
    <img src="initial.png" alt="Original status"/>
    <div class="subfigure-caption">(a) Initial state</div>
  </div>
  <div class="subfigure">
    <img src="cmarl.png" alt="Our planning outcome"/>
    <div class="subfigure-caption"><strong>(b) Our planning outcome</strong></div>
  </div>
</div>
<div class="figure-caption">
  Figure 3: Comparisons of our MARL readjustment outcome and original status of land use distribution in Kendall Square.
</div>


<!-- ## Baseline algorithm
In our study, conducted within both top-down and participatory planning environments, we select four methods as baselines for comparison: the random method, the greedy method, DRL and our proposed method. Specifically:
1. The random method, Random Top-down Planning (Random-TP) and Random Participatory Planning (Random-PP), allows each agent to vote for a land-use type based on random selection.
2. The greedy method, Greedy Top-down Planning (Greedy-TP) and Greedy Participatory Planning (Greedy-PP) enables agents to vote for the land-use type that is most beneficial to them individually, neglecting the global impact.
3. The DRL method, DRL Top-down Planning (DRL-TP) is employed in top-down planning, centralizing decision-making of land readjustment.

## Algorithmic metrics
To assess the performance of compared methods from an algorithmic standpoint, we focused on two key rewards, Global Reward and Equity Reward, derived from the reward metrics aforementioned: global awareness and equity awareness. Utilizing these metrics quantifies the capability of each approach to not only optimize land use distribution in alignment with overarching urban development goals but also to balance individual interests, emphasizing social equity in the decision-making process. Thus, we focus on maximizing the Global Reward and simultaneously minimizing the Equity Reward in the experiment.

Table 1: Algorithmic effectiveness comparisons
| Methods       | Global reward | Equity reward |
|:-------------:|:-------------:|:-------------:|
| Random-TP     | 0.958         | 36084.443     |
| Random-PP     | 0.942         | 38697.276     |
| Greedy-TP     | 0.965         | 42117.190     |
| Greedy-PP     | 0.962         | 35328.027     |
| DRL-TP        | 1.018         | 40532.082     |
| **Our method**| **1.018**     | **28240.209** |


## Urban metrics
Beyond the algorithmic metrics, the outcomes proposed by each method are assessed from urban planning perspectives, specifically examining the potential improvement in the quality of life for agents in the region. In [the government planning guideline of Kendall Square](https://www.cambridgeredevelopment.org/kendall-square-3), four planning metrics, sustainability, innovation, service, and diversity, stand out as crucial determinants of its planning targets.

Table 2: Urban metrics comparisons
| Methods       | Sustainability | Innovation | Service | Diversity |
|:-------------:|:--------------:|:----------:|:-------:|:---------:|
| Initial state | 0.11           | 0.36       | 0.39    | 0.82      |
| Random-TP     | 0.19           | 0.48       | 0.38    | 0.82      |
| Random-PP     | 0.15           | 0.47       | 0.39    | 0.82      |
| Greedy-TP     | 0.17           | 0.47       | 0.38    | 0.81      |
| Greedy-PP     | 0.17           | 0.48       | 0.38    | 0.86      |
| DRL-TP        | 0.27           | 0.48       | 0.41    | 0.86      |
| **Our method**| **0.63**       | **0.79**   | **0.41**| **1.42**  | -->

<h1 id="Paper-link"><a href="#Paper-link" class="headerlink" title="Paper link"></a>Paper link</h1><p>View our paper: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.16772">ArXivL:2310.16772</a></p>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Gallery</a></li>
         
          <li><a target="_blank" rel="noopener" href="https://scholar.google.com/citations?user=x6fPDh4AAAAJ&hl=zh-CN&oi=ao">Research</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Authors"><span class="toc-number">1.</span> <span class="toc-text">Authors</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Highlights"><span class="toc-number">2.</span> <span class="toc-text">Highlights</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Background"><span class="toc-number">3.</span> <span class="toc-text">Background</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Aim-amp-Methodology"><span class="toc-number">4.</span> <span class="toc-text">Aim &amp; Methodology</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Results"><span class="toc-number">5.</span> <span class="toc-text">Results</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Planning-outcomes"><span class="toc-number">5.1.</span> <span class="toc-text">Planning outcomes</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Paper-link"><span class="toc-number">6.</span> <span class="toc-text">Paper link</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2023/10/25/ai-urban-planner/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2023/10/25/ai-urban-planner/&text=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2023/10/25/ai-urban-planner/&title=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2023/10/25/ai-urban-planner/&is_video=false&description=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning&body=Check out this article: http://example.com/2023/10/25/ai-urban-planner/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2023/10/25/ai-urban-planner/&title=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2023/10/25/ai-urban-planner/&title=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2023/10/25/ai-urban-planner/&title=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2023/10/25/ai-urban-planner/&title=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2023/10/25/ai-urban-planner/&name=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2023/10/25/ai-urban-planner/&t=AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban Planning via Consensus-based Multi-Agent Reinforcement Learning"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2023-2024
    Kejiang Qian
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Gallery</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="https://scholar.google.com/citations?user=x6fPDh4AAAAJ&hl=zh-CN&oi=ao">Research</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->
 
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script> 




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script> 
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Umami Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>
